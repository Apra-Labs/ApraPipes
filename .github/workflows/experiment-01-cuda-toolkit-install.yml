name: Experiment-01-CUDA-Toolkit-Install

# EXPERIMENT: Can we install CUDA toolkit on ubuntu-latest without GPU?
# SUCCESS CRITERIA:
#   1. CUDA toolkit installs without errors
#   2. nvcc compiler is available
#   3. Simple CUDA code compiles
#   4. cudaGetDeviceCount() runs without crash (returns 0 devices is OK)

on:
  workflow_dispatch:  # Manual trigger only
  push:
    branches:
      - feature/get-rid-of-nocuda-builds
    paths:
      - '.github/workflows/experiment-01-cuda-toolkit-install.yml'

jobs:
  test-cuda-install-ubuntu:
    runs-on: ubuntu-latest

    steps:
      - name: Install CUDA Toolkit 11.8
        run: |
          echo "=== Installing CUDA Toolkit 11.8 ==="

          # Check Ubuntu version
          lsb_release -a

          # Add Universe repository (required for some dependencies)
          sudo add-apt-repository universe

          # Add NVIDIA CUDA repository
          wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
          sudo dpkg -i cuda-keyring_1.0-1_all.deb
          sudo apt-get update

          # Install CUDA toolkit WITHOUT nsight-systems (which has libtinfo5 dependency issue on Ubuntu 24.04)
          # Install core toolkit components only
          sudo apt-get -y install cuda-cudart-11-8 cuda-nvcc-11-8 \
              cuda-libraries-11-8 cuda-libraries-dev-11-8 \
              cuda-runtime-11-8

          echo "=== CUDA Installation Complete ==="

      - name: Verify CUDA Installation
        run: |
          echo "=== Verifying CUDA Installation ==="

          export PATH=/usr/local/cuda-11.8/bin:$PATH
          export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH

          echo "CUDA Path: $(which nvcc)"
          nvcc --version

          echo "=== CUDA Verification Complete ==="

      - name: Test CUDA Compilation
        run: |
          echo "=== Testing CUDA Compilation ==="

          export PATH=/usr/local/cuda-11.8/bin:$PATH
          export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH

          # Create simple CUDA test program
          cat > test_cuda.cu << 'EOF'
          #include <cuda_runtime.h>
          #include <stdio.h>

          int main() {
              printf("=== CUDA Runtime Test ===\n");

              int deviceCount = 0;
              cudaError_t error = cudaGetDeviceCount(&deviceCount);

              printf("cudaGetDeviceCount returned: %d (%s)\n",
                     error, cudaGetErrorString(error));
              printf("Device count: %d\n", deviceCount);

              if (error == cudaSuccess) {
                  printf("SUCCESS: CUDA runtime works (no GPU is OK)\n");
                  return 0;
              } else if (error == cudaErrorNoDevice ||
                         error == cudaErrorInsufficientDriver) {
                  printf("SUCCESS: CUDA runtime works, no GPU available (expected on GitHub runner)\n");
                  return 0;
              } else {
                  printf("FAILURE: Unexpected CUDA error\n");
                  return 1;
              }
          }
          EOF

          # Compile with nvcc
          nvcc test_cuda.cu -o test_cuda
          echo "Compilation successful!"

          # Run the test
          ./test_cuda

          echo "=== Test Complete ==="

      - name: Test CUDA Static Runtime Linking
        run: |
          echo "=== Testing Static CUDA Runtime ==="

          export PATH=/usr/local/cuda-11.8/bin:$PATH
          export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH

          # Create test with static runtime
          cat > test_static.cu << 'EOF'
          #include <cuda_runtime.h>
          #include <stdio.h>

          __global__ void dummy_kernel() {
              // Empty kernel for testing
          }

          int main() {
              printf("=== Static Runtime Test ===\n");

              // Test device query
              int deviceCount = 0;
              cudaError_t error = cudaGetDeviceCount(&deviceCount);
              printf("Device count query: %s\n", cudaGetErrorString(error));

              // Test memory allocation (will fail without GPU, but shouldn't crash)
              void* ptr = nullptr;
              error = cudaMalloc(&ptr, 1024);
              printf("cudaMalloc: %s (failure expected without GPU)\n",
                     cudaGetErrorString(error));
              if (ptr) cudaFree(ptr);

              printf("SUCCESS: Static runtime links and runs\n");
              return 0;
          }
          EOF

          # Compile with static runtime
          nvcc test_static.cu -o test_static \
               -cudart static \
               -lcudart_static -ldl -lrt -lpthread

          echo "Static linking successful!"

          # Check binary for dynamic CUDA dependencies
          echo "Checking dynamic dependencies:"
          ldd test_static | grep cuda || echo "No dynamic CUDA dependencies (good!)"

          # Run test
          ./test_static

          echo "=== Static Runtime Test Complete ==="

      - name: Summary
        if: always()
        run: |
          echo ""
          echo "======================================"
          echo "EXPERIMENT 01: RESULTS"
          echo "======================================"
          echo ""
          echo "This experiment validates:"
          echo "  ✓ CUDA toolkit can be installed on GitHub runners"
          echo "  ✓ nvcc compiler works without GPU hardware"
          echo "  ✓ CUDA runtime API compiles and links"
          echo "  ✓ cudaGetDeviceCount() runs without crash"
          echo "  ✓ Static CUDA runtime works (no .so dependencies)"
          echo ""
          echo "Next Step: Experiment 02 - vcpkg opencv4[cuda]"
          echo "======================================"
